"""
Autonomous Conversation Engine - Silnik autonomicznych rozm√≥w Rady Partner√≥w
Partnerzy rozmawiajƒÖ ze sobƒÖ nawet gdy ZarzƒÖdzajƒÖcego nie ma
"""

import json
import os
import random
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from api_usage_tracker import get_tracker
import anthropic
import google.generativeai as genai
from openai import OpenAI

# Import Nexus AI Engine
try:
    from nexus_ai_engine import get_nexus_engine
    NEXUS_AVAILABLE = True
except Exception as e:
    print(f"‚ö†Ô∏è Nexus AI Engine niedostƒôpny: {e}")
    NEXUS_AVAILABLE = False

# Import konfiguracji z g≈Ç√≥wnego pliku
try:
    from streamlit_app import (
        PERSONAS,
        wczytaj_kodeks, wczytaj_cele, wczytaj_stan_spolki
    )
    IMPORT_OK = True
except Exception as e:
    print(f"‚ö†Ô∏è Nie mo≈ºna zaimportowaƒá z streamlit_app.py: {e}")
    IMPORT_OK = False
    PERSONAS = {}

# API Keys zawsze z .env (bezpieczniej ni≈º import z streamlit_app)
from dotenv import load_dotenv
load_dotenv()
ANTHROPIC_KEY = os.getenv("ANTHROPIC_API_KEY")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")
OPENROUTER_KEY = os.getenv("OPENROUTER_API_KEY")

# Je≈õli PERSONAS nie za≈Çadowano z streamlit_app, spr√≥buj z gra_rpg
if not PERSONAS:
    try:
        import sys
        sys.path.insert(0, os.path.dirname(__file__))
        from gra_rpg import PERSONAS as PERSONAS_FROM_RPG
        PERSONAS = PERSONAS_FROM_RPG
        print("‚úÖ Za≈Çadowano PERSONAS z gra_rpg.py")
    except:
        print("‚ö†Ô∏è Nie mo≈ºna za≈Çadowaƒá PERSONAS")

# Pliki danych
CONVERSATIONS_FILE = "autonomous_conversations.json"
TOPICS_FILE = "autonomous_topics_config.json"

# Domy≈õlne tematy rozm√≥w
DEFAULT_TOPICS = {
    "portfolio_analysis": {
        "name": "Analiza Portfela",
        "description": "PrzeglƒÖd aktualnego stanu portfela i jego alokacji",
        "priority": "MEDIUM",
        "frequency": "daily",
        "prompt_template": "Przeanalizujmy aktualny stan portfela. Warto≈õƒá akcji: {stocks_value} PLN, Krypto: {crypto_value} USD, D≈Çugi: {debt_value} PLN. Jak oceniacie obecnƒÖ alokacjƒô?"
    },
    "market_trends": {
        "name": "Trendy Rynkowe",
        "description": "Dyskusja o aktualnych trendach na rynkach",
        "priority": "LOW",
        "frequency": "weekly",
        "prompt_template": "Co sƒÖdzicie o aktualnych trendach rynkowych? Bitcoin ostatnio {btc_trend}, rynek akcji {stock_trend}."
    },
    "risk_assessment": {
        "name": "Ocena Ryzyka",
        "description": "Analiza ryzyka w portfelu",
        "priority": "HIGH",
        "frequency": "daily",
        "prompt_template": "Przeanalizujmy poziom ryzyka w portfelu. Czy jeste≈õmy odpowiednio zdywersyfikowani? Jakie sƒÖ najwiƒôksze zagro≈ºenia?"
    },
    "goals_review": {
        "name": "PrzeglƒÖd Cel√≥w",
        "description": "Dyskusja o postƒôpach w realizacji cel√≥w",
        "priority": "MEDIUM",
        "frequency": "weekly",
        "prompt_template": "Sprawd≈∫my postƒôpy w realizacji naszych cel√≥w finansowych. Czy jeste≈õmy na dobrej drodze?"
    },
    "strategy_debate": {
        "name": "Debata Strategiczna",
        "description": "Dyskusja o d≈Çugoterminowej strategii",
        "priority": "HIGH",
        "frequency": "weekly",
        "prompt_template": "Porozmawiajmy o naszej d≈Çugoterminowej strategii inwestycyjnej. Czy powinna siƒô zmieniƒá? Co dostosowaƒá?"
    },
    "nexus_meta_discussion": {
        "name": "Meta-Dyskusja o Radzie",
        "description": "Nexus moderuje dyskusjƒô o efektywno≈õci wsp√≥≈Çpracy Rady",
        "priority": "MEDIUM",
        "frequency": "monthly",
        "prompt_template": "Nexus zaprasza do refleksji: Jak oceniacie naszƒÖ wsp√≥≈Çpracƒô jako Rada? Co dzia≈Ça dobrze? Co mogliby≈õmy poprawiƒá w naszych dyskusjach?"
    },
    "ai_voting_weights": {
        "name": "PrzeglƒÖd Wag G≈Ços√≥w",
        "description": "Dyskusja o systemie scoring i wagach g≈Ços√≥w partner√≥w",
        "priority": "LOW",
        "frequency": "monthly",
        "prompt_template": "Porozmawiajmy o systemie dynamicznych wag g≈Ços√≥w. Czy obecny system scoring dobrze odzwierciedla warto≈õƒá waszych porad? Jak go ulepszyƒá?"
    },
    "knowledge_gaps": {
        "name": "Luki Wiedzy",
        "description": "Identyfikacja obszar√≥w gdzie Rada potrzebuje wiƒôcej expertise",
        "priority": "MEDIUM",
        "frequency": "monthly",
        "prompt_template": "Jakie sƒÖ nasze najwiƒôksze luki wiedzy? W jakich obszarach potrzebujemy lepszych analiz lub dodatkowych ≈∫r√≥de≈Ç informacji?"
    }
}


class AutonomousConversationEngine:
    """Silnik autonomicznych rozm√≥w"""
    
    def __init__(self):
        self.tracker = get_tracker()
        self.topics_config = self._load_topics_config()
        self.conversations_db = self._load_conversations()
        
        # Konfiguruj AI clients
        self.claude_client = anthropic.Anthropic(api_key=ANTHROPIC_KEY) if ANTHROPIC_KEY else None
        if GEMINI_KEY:
            genai.configure(api_key=GEMINI_KEY)
        
        # OpenRouter client (NIE standardowy OpenAI!)
        if OPENROUTER_KEY:
            self.openai_client = OpenAI(
                api_key=OPENROUTER_KEY,
                base_url="https://openrouter.ai/api/v1"
            )
        else:
            self.openai_client = None
        
        print("‚úÖ Autonomous Conversation Engine initialized")
    
    def _load_topics_config(self) -> Dict:
        """Za≈Çaduj konfiguracjƒô temat√≥w"""
        if os.path.exists(TOPICS_FILE):
            with open(TOPICS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            self._save_topics_config(DEFAULT_TOPICS)
            return DEFAULT_TOPICS
    
    def _save_topics_config(self, config: Dict):
        """Zapisz konfiguracjƒô temat√≥w"""
        with open(TOPICS_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def _load_conversations(self) -> List[Dict]:
        """Za≈Çaduj historiƒô rozm√≥w"""
        if os.path.exists(CONVERSATIONS_FILE):
            with open(CONVERSATIONS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return []
    
    def _save_conversation(self, conversation: Dict):
        """Zapisz rozmowƒô do bazy"""
        self.conversations_db.append(conversation)
        
        # Zachowaj ostatnie 100 rozm√≥w
        if len(self.conversations_db) > 100:
            self.conversations_db = self.conversations_db[-100:]
        
        with open(CONVERSATIONS_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.conversations_db, f, indent=2, ensure_ascii=False)
    
    def check_api_budget(self) -> Tuple[bool, str]:
        """
        Sprawd≈∫ czy jest dostƒôpny bud≈ºet API dla autonomicznej rozmowy
        
        Returns:
            (can_proceed, message)
        """
        budgets = self.tracker.get_all_budgets()
        
        # Sprawd≈∫ czy kt√≥rekolwiek API ma dostƒôpny bud≈ºet
        available_apis = []
        for api_name, budget in budgets.items():
            if budget["autonomous"]["remaining"] > 8:  # Min 8 wywo≈Ça≈Ñ na rozmowƒô (4 partner√≥w x 2)
                available_apis.append(api_name)
        
        if not available_apis:
            return False, "üö´ Brak dostƒôpnego bud≈ºetu API dla autonomicznych rozm√≥w dzisiaj"
        
        return True, f"‚úÖ Dostƒôpne API: {', '.join(available_apis)}"
    
    def select_topic(self) -> Tuple[str, Dict]:
        """
        Wybierz temat do dyskusji
        
        Returns:
            (topic_id, topic_config)
        """
        # Mo≈ºesz dodaƒá bardziej zaawansowanƒÖ logikƒô (np. AI decyduje)
        # Na razie: losowy temat z HIGH priority
        
        high_priority = {k: v for k, v in self.topics_config.items() if v.get("priority") == "HIGH"}
        
        if high_priority:
            topic_id = random.choice(list(high_priority.keys()))
        else:
            topic_id = random.choice(list(self.topics_config.keys()))
        
        return topic_id, self.topics_config[topic_id]
    
    def generate_opening_prompt(self, topic: Dict) -> str:
        """Wygeneruj poczƒÖtkowy prompt rozmowy"""
        template = topic.get("prompt_template", "Porozmawiajmy o {topic_name}")
        
        # Podstaw rzeczywiste dane (je≈õli IMPORT_OK)
        try:
            stan_spolki = wczytaj_stan_spolki() if IMPORT_OK else {}
            
            prompt = template.format(
                stocks_value=stan_spolki.get('akcje_wartosc', 0),
                crypto_value=stan_spolki.get('krypto_wartosc', 0),
                debt_value=stan_spolki.get('dlugi_laczne', 0),
                btc_trend="ro≈õnie" if random.random() > 0.5 else "spada",
                stock_trend="stabilny" if random.random() > 0.5 else "zmniejsza siƒô",
                topic_name=topic.get("name", "temat")
            )
        except:
            prompt = f"Porozmawiajmy o: {topic.get('name', 'strategii')}"
        
        return prompt
    
    def select_participants(self, topic: Dict) -> List[str]:
        """
        Wybierz uczestnik√≥w rozmowy (4 partner√≥w)
        
        WA≈ªNE: Wykluczamy "Partner ZarzƒÖdzajƒÖcy (JA)" - to fizyczna osoba!
        Autonomiczne rozmowy = tylko AI partners bez u≈ºytkownika
        """
        if not PERSONAS:
            return ["Nexus", "Warren Buffett", "George Soros", "Changpeng Zhao (CZ)"]
        
        all_partners = list(PERSONAS.keys())
        
        # ‚ùå WYKLUCZAMY "Partner ZarzƒÖdzajƒÖcy (JA)" z autonomicznych rozm√≥w!
        ai_only_partners = [p for p in all_partners if p != "Partner ZarzƒÖdzajƒÖcy (JA)"]
        
        # Wybierz 4 AI partner√≥w (Nexus, Warren, Soros, CZ)
        # Mo≈ºesz dodaƒá logikƒô: risk topics = Soros first, value = Buffett first, crypto = CZ first
        participants = ai_only_partners[:4] if len(ai_only_partners) >= 4 else ai_only_partners
        
        return participants
    
    def call_ai_partner(self, partner_name: str, prompt: str, context: List[Dict]) -> Optional[str]:
        """
        Wy≈õlij prompt do AI partnera
        
        Args:
            partner_name: Nazwa partnera
            prompt: G≈Ç√≥wny prompt
            context: Lista poprzednich wiadomo≈õci [{"partner": "...", "message": "..."}]
        
        Returns:
            Odpowied≈∫ AI lub None je≈õli b≈ÇƒÖd
        """
        if not PERSONAS or partner_name not in PERSONAS:
            return None
        
        persona = PERSONAS[partner_name]
        model_engine = persona.get("model_engine", "gemini")
        
        # ‚ú® NEXUS HANDLING - u≈ºywa nexus_ai_engine.py
        if model_engine == "nexus" and NEXUS_AVAILABLE:
            try:
                nexus = get_nexus_engine()
                
                # Przygotuj kontekst dla Nexusa
                nexus_context = {
                    'conversation_type': 'autonomous',
                    'topic': prompt,
                    'previous_messages': context[-3:] if context else [],
                    'participant_count': len(set([msg.get('partner') for msg in context])) if context else 0
                }
                
                # Nexus prompt - jest moderatorem rozmowy
                nexus_prompt = f"""Jeste≈õ Nexus - meta-advisor koordynujƒÖcy Radƒô Partner√≥w.

To jest AUTONOMICZNA rozmowa (ZarzƒÖdzajƒÖcego nie ma). 
Rozmawiasz z {', '.join([msg.get('partner', '?') for msg in context[-3:]])} o temacie: {prompt}

Twoja rola:
- Syntetyzuj r√≥≈ºne perspektywy
- Wskazuj consensus lub g≈Ç√≥wne r√≥≈ºnice
- Zadawaj pytania prowokujƒÖce g≈ÇƒôbszƒÖ dyskusjƒô
- BƒÖd≈∫ zwiƒôz≈Çy (3-4 zdania max)

POPRZEDNIE WYPOWIEDZI:
{chr(10).join([f"{msg['partner']}: {msg['message']}" for msg in context[-3:]]) if context else "Brak poprzednich wypowiedzi"}

Twoja odpowied≈∫ (jako moderator, zwiƒô≈∫le):"""
                
                result = nexus.generate_response(nexus_prompt, context=nexus_context)
                
                if result.get('success'):
                    answer = result.get('response', '')
                    
                    # Oczy≈õƒá odpowied≈∫
                    answer = answer.strip()
                    for token in ['<s>', '</s>', '<|endoftext|>', '<|im_end|>', 'ÔøΩ']:
                        answer = answer.replace(token, '')
                    answer = answer.strip()
                    
                    # Track API call (Nexus u≈ºywa Gemini w single mode)
                    self.tracker.track_call('gemini', is_autonomous=True)
                    
                    return answer
                else:
                    print(f"‚ö†Ô∏è Nexus zwr√≥ci≈Ç b≈ÇƒÖd: {result.get('error')}")
                    return None
                    
            except Exception as e:
                print(f"‚ùå B≈ÇƒÖd wywo≈Çania Nexus: {e}")
                return None
        
        # Mapuj model_engine na api_type dla trackera
        if model_engine.startswith("openrouter"):
            api_type = "openai"  # OpenRouter u≈ºywa OpenAI API
        else:
            api_type = model_engine  # "gemini" lub "claude"
        
        # Sprawd≈∫ bud≈ºet przed wywo≈Çaniem
        if not self.tracker.can_make_autonomous_call(api_type):
            print(f"‚ö†Ô∏è Brak bud≈ºetu {api_type} dla {partner_name}")
            return None
        
        # Przygotuj pe≈Çny prompt z kontekstem
        full_prompt = f"""Jeste≈õ {partner_name}.

{persona.get('opis', '')}

WA≈ªNE: To jest autonomiczna rozmowa Rady Partner√≥w (ZarzƒÖdzajƒÖcego nie ma).
Rozmawiasz z kolegami z Rady. BƒÖd≈∫ zwiƒôz≈Çy (max 3-4 zdania).
"""
        
        # Dodaj kontekst poprzednich wypowiedzi
        if context:
            full_prompt += "\n\nüí¨ POPRZEDNIE WYPOWIEDZI:\n"
            for msg in context[-3:]:  # Ostatnie 3 wiadomo≈õci
                full_prompt += f"{msg['partner']}: {msg['message']}\n"
        
        full_prompt += f"\n\nTemat dyskusji: {prompt}\n\nTwoja odpowied≈∫ (zwiƒô≈∫le, 3-4 zdania):"
        
        # Wywo≈Çaj odpowiednie API na podstawie model_engine
        try:
            # OPENROUTER (wszystkie modele openrouter_*)
            if model_engine.startswith("openrouter") and self.openai_client:
                # Mapuj model_engine na konkretny model OpenRouter (z :free!)
                model_map = {
                    "openrouter_mistral": "mistralai/mistral-7b-instruct:free",
                    "openrouter_llama": "meta-llama/llama-4-maverick:free",
                    "openrouter_mixtral": "meta-llama/llama-4-scout:free",
                    "openrouter_glm": "z-ai/glm-4.5-air:free"
                }
                model_name = model_map.get(model_engine, "mistralai/mistral-7b-instruct:free")
                
                response = self.openai_client.chat.completions.create(
                    model=model_name,
                    max_tokens=300,
                    messages=[{"role": "user", "content": full_prompt}]
                )
                answer = response.choices[0].message.content
                
            # GEMINI
            elif model_engine == "gemini":
                model = genai.GenerativeModel('gemini-2.0-flash-exp')
                response = model.generate_content(full_prompt)
                answer = response.text
                
            # CLAUDE
            elif model_engine == "claude" and self.claude_client:
                response = self.claude_client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=300,
                    messages=[{"role": "user", "content": full_prompt}]
                )
                answer = response.content[0].text
            else:
                print(f"‚ùå Nieznany model_engine: {model_engine}")
                return None
            
            # Oczy≈õƒá odpowied≈∫ z token√≥w specjalnych
            answer = answer.strip()
            # Usu≈Ñ tokeny: <s>, </s>, <|endoftext|>, itp.
            for token in ['<s>', '</s>', '<|endoftext|>', '<|im_end|>', 'ÔøΩ']:
                answer = answer.replace(token, '')
            answer = answer.strip()
            
            # Zarejestruj wywo≈Çanie
            self.tracker.track_call(api_type, is_autonomous=True)
            
            return answer
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd wywo≈Çania {api_type} dla {partner_name}: {e}")
            return None
    
    def run_conversation(self, max_messages: int = 12) -> Optional[Dict]:
        """
        Uruchom autonomicznƒÖ rozmowƒô
        
        Args:
            max_messages: Maksymalna liczba wiadomo≈õci (domy≈õlnie 12)
        
        Returns:
            Dict z rozmowƒÖ lub None je≈õli b≈ÇƒÖd
        """
        print("\n" + "="*60)
        print("ü§ñ AUTONOMOUS CONVERSATION ENGINE - START")
        print("="*60)
        
        # 1. Sprawd≈∫ bud≈ºet API
        can_proceed, budget_msg = self.check_api_budget()
        print(budget_msg)
        
        if not can_proceed:
            return None
        
        # 2. Wybierz temat
        topic_id, topic = self.select_topic()
        print(f"üìã Temat: {topic['name']} (Priority: {topic['priority']})")
        
        # 3. Wybierz uczestnik√≥w
        participants = self.select_participants(topic)
        print(f"üë• Uczestnicy: {', '.join(participants)}")
        
        # 4. Wygeneruj opening prompt
        opening_prompt = self.generate_opening_prompt(topic)
        print(f"üí¨ Opening: {opening_prompt[:100]}...")
        
        # 5. Rozpocznij rozmowƒô
        conversation = {
            "id": f"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "date": datetime.now().isoformat(),
            "topic_id": topic_id,
            "topic_name": topic['name'],
            "opening_prompt": opening_prompt,  # ‚úÖ DODANE: Pe≈Çny tekst opening
            "participants": participants,
            "messages": [],
            "status": "in_progress",
            "api_calls_used": 0
        }
        
        context = []
        
        for i in range(max_messages):
            # Rotuj uczestnik√≥w
            current_partner = participants[i % len(participants)]
            
            print(f"\n[{i+1}/{max_messages}] üó£Ô∏è {current_partner} odpowiada...")
            
            # Wywo≈Çaj AI
            response = self.call_ai_partner(current_partner, opening_prompt, context)
            
            if response:
                message = {
                    "partner": current_partner,
                    "message": response,
                    "timestamp": datetime.now().isoformat(),
                    "message_number": i + 1
                }
                
                conversation["messages"].append(message)
                context.append({"partner": current_partner, "message": response})
                conversation["api_calls_used"] += 1
                
                print(f"   ‚úÖ {response[:150]}...")
            else:
                print(f"   ‚ö†Ô∏è Brak odpowiedzi (limit API?)")
                # Je≈õli 3 kolejne b≈Çƒôdy, przerwij
                if i > 0 and all(m is None for m in conversation["messages"][-3:]):
                    print("   üö´ Zbyt wiele b≈Çƒôd√≥w, przerywam rozmowƒô")
                    break
        
        # 6. Zako≈Ñcz rozmowƒô
        conversation["status"] = "completed"
        conversation["completed_at"] = datetime.now().isoformat()
        
        # 7. Zapisz do bazy
        self._save_conversation(conversation)
        self.tracker.increment_autonomous_conversation()
        
        print(f"\n‚úÖ Rozmowa zako≈Ñczona: {len(conversation['messages'])} wiadomo≈õci")
        print(f"üíæ Zapisano jako: {conversation['id']}")
        
        # 8. Wygeneruj AI Summary (je≈õli sƒÖ wiadomo≈õci)
        if len(conversation['messages']) > 0:
            print(f"ü§ñ Generujƒô AI Summary...")
            summary = self._generate_summary(conversation)
            if summary:
                conversation['summary'] = summary
                print(f"‚úÖ Summary wygenerowane")
        
        # 8b. ‚ú® NEXUS META-ANALYSIS (je≈õli dostƒôpny)
        if NEXUS_AVAILABLE and len(conversation['messages']) >= 3:
            print(f"ü§ñ Nexus przeprowadza meta-analizƒô...")
            meta_analysis = self.nexus_meta_analysis(conversation)
            if meta_analysis:
                conversation['nexus_meta_analysis'] = meta_analysis
                print(f"‚úÖ Nexus meta-analysis uko≈Ñczona")
                print(f"   Jako≈õƒá rozmowy: {meta_analysis.get('overall_quality', 0):.0%}")
        
        # Zapisz ze wszystkimi analizami
        self._save_conversation(conversation)
        
        # 9. Wy≈õlij email notification (je≈õli w≈ÇƒÖczone)
        try:
            from email_notifier import get_conversation_notifier
            notifier = get_conversation_notifier()
            if notifier.config.get("enabled", False):
                notifier.send_conversation_completed(conversation)
                print(f"üìß Email notification wys≈Çany")
        except Exception as e:
            print(f"‚ö†Ô∏è Nie mo≈ºna wys≈Çaƒá email notification: {e}")
        
        print("="*60 + "\n")
        
        return conversation
    
    def _generate_summary(self, conversation: Dict) -> Optional[Dict]:
        """
        Wygeneruj AI summary rozmowy u≈ºywajƒÖc Gemini
        
        Returns:
            Dict z polami: summary, key_points, sentiment
            None je≈õli b≈ÇƒÖd
        """
        try:
            messages = conversation.get("messages", [])
            if not messages:
                return None
            
            # Zbuduj transkrypt
            transcript = "\n".join([
                f"{msg.get('partner', 'Unknown')}: {msg.get('message', '')[:300]}"  # Max 300 znak√≥w na msg
                for msg in messages
            ])
            
            topic_name = conversation.get("topic_name", "Unknown Topic")
            
            prompt = f"""Przeanalizuj tƒô rozmowƒô Rady Partner√≥w i wygeneruj zwiƒôz≈Çe podsumowanie.

TEMAT ROZMOWY: {topic_name}

TRANSKRYPT:
{transcript}

Wygeneruj odpowied≈∫ w formacie JSON z nastƒôpujƒÖcymi polami:
1. "summary": Kr√≥tkie podsumowanie rozmowy (2-3 zdania max)
2. "key_points": Lista 3 najwa≈ºniejszych wniosk√≥w (kr√≥tkie zdania)
3. "sentiment": "positive" lub "neutral" lub "negative" (og√≥lny ton rozmowy)

Odpowied≈∫ TYLKO w formacie JSON, bez dodatkowego tekstu:
"""
            
            # Wywo≈Çaj Gemini
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            response = model.generate_content(prompt)
            
            # Parse JSON
            response_text = response.text.strip()
            
            # Usu≈Ñ markdown code blocks je≈õli sƒÖ
            if response_text.startswith('```'):
                response_text = response_text.split('```')[1]
                if response_text.startswith('json'):
                    response_text = response_text[4:]
                response_text = response_text.strip()
            
            summary_data = json.loads(response_text)
            
            # Track API call
            self.tracker.track_call('gemini', is_autonomous=True)
            
            return summary_data
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd generowania summary: {e}")
            return None
    
    def get_recent_conversations(self, limit: int = 10) -> List[Dict]:
        """Zwr√≥ƒá ostatnie N rozm√≥w"""
        return sorted(self.conversations_db, key=lambda x: x.get("date", ""), reverse=True)[:limit]
    
    def get_conversation_by_id(self, conv_id: str) -> Optional[Dict]:
        """Zwr√≥ƒá konkretnƒÖ rozmowƒô po ID"""
        for conv in self.conversations_db:
            if conv.get("id") == conv_id:
                return conv
        return None
    
    # ============================================================================
    # NEXUS ENHANCED FEATURES - Meta-analysis, Voting Simulation, Knowledge Synthesis
    # ============================================================================
    
    def nexus_meta_analysis(self, conversation: Dict) -> Optional[Dict]:
        """
        ü§ñ Nexus przeprowadza meta-analizƒô rozmowy
        
        Analizuje:
        - G≈Ç√≥wne trendy w dyskusji
        - Punkty zgody i sporu
        - Quality score wypowiedzi ka≈ºdego partnera
        - Rekomendacje dla przysz≈Çych dyskusji
        
        Args:
            conversation: Dict z zako≈ÑczonƒÖ rozmowƒÖ
        
        Returns:
            Dict z meta-analizƒÖ lub None
        """
        if not NEXUS_AVAILABLE:
            print("‚ö†Ô∏è Nexus niedostƒôpny - meta-analysis pomiƒôta")
            return None
        
        messages = conversation.get("messages", [])
        if len(messages) < 3:
            print("‚ö†Ô∏è Za ma≈Ço wiadomo≈õci do meta-analizy (min 3)")
            return None
        
        try:
            nexus = get_nexus_engine()
            
            # Zbuduj transkrypt
            transcript = "\n".join([
                f"[{msg.get('message_number', '?')}] {msg.get('partner', 'Unknown')}: {msg.get('message', '')}"
                for msg in messages
            ])
            
            topic_name = conversation.get("topic_name", "Unknown")
            opening_prompt = conversation.get("opening_prompt", "")
            
            analysis_prompt = f"""Przeprowad≈∫ META-ANALIZƒò tej autonomicznej rozmowy Rady Partner√≥w.

TEMAT: {topic_name}
OPENING: {opening_prompt}
LICZBA WYPOWIEDZI: {len(messages)}
UCZESTNICY: {', '.join(conversation.get('participants', []))}

TRANSKRYPT ROZMOWY:
{transcript}

Przeanalizuj i zwr√≥ƒá TYLKO JSON z nastƒôpujƒÖcymi polami:
{{
    "main_themes": ["temat1", "temat2", "temat3"],
    "consensus_points": ["punkt zgody 1", "punkt zgody 2"],
    "disagreement_points": ["punkt sporu 1", "punkt sporu 2"],
    "partner_quality_scores": {{
        "Partner1": {{"score": 0.8, "reason": "dlaczego"}},
        "Partner2": {{"score": 0.6, "reason": "dlaczego"}}
    }},
    "key_insights": ["insight 1", "insight 2", "insight 3"],
    "recommendations": ["rekomendacja 1", "rekomendacja 2"],
    "overall_quality": 0.75
}}

JSON (bez dodatkowego tekstu):"""
            
            context = {'conversation_analysis': True}
            result = nexus.generate_response(analysis_prompt, context=context)
            
            if result.get('success'):
                # Parse JSON z odpowiedzi
                response_text = result.get('response', '').strip()
                
                # Usu≈Ñ markdown blocks
                if response_text.startswith('```'):
                    response_text = response_text.split('```')[1]
                    if response_text.startswith('json'):
                        response_text = response_text[4:]
                    response_text = response_text.strip()
                
                meta_analysis = json.loads(response_text)
                
                print(f"‚úÖ Nexus Meta-Analysis completed")
                print(f"   Main themes: {len(meta_analysis.get('main_themes', []))}")
                print(f"   Overall quality: {meta_analysis.get('overall_quality', 0)}")
                
                return meta_analysis
            else:
                print(f"‚ùå Nexus meta-analysis failed: {result.get('error')}")
                return None
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd meta-analysis: {e}")
            return None
    
    def nexus_voting_simulation(self, conversation: Dict, decision_question: str) -> Optional[Dict]:
        """
        üó≥Ô∏è Nexus symuluje g≈Çosowanie na podstawie rozmowy
        
        Na podstawie analizy wypowiedzi partner√≥w w rozmowie,
        Nexus przewiduje jak zag≈Çosowaliby na konkretnƒÖ decyzjƒô.
        
        Args:
            conversation: Dict z zako≈ÑczonƒÖ rozmowƒÖ
            decision_question: Pytanie decyzyjne (np. "Czy zwiƒôkszyƒá alokacjƒô w krypto do 30%?")
        
        Returns:
            Dict z symulacjƒÖ g≈Çosowania lub None
        """
        if not NEXUS_AVAILABLE:
            print("‚ö†Ô∏è Nexus niedostƒôpny - voting simulation pomiƒôta")
            return None
        
        messages = conversation.get("messages", [])
        if len(messages) < 3:
            print("‚ö†Ô∏è Za ma≈Ço wiadomo≈õci do voting simulation")
            return None
        
        try:
            nexus = get_nexus_engine()
            
            # Grupuj wiadomo≈õci po partnerach
            partner_statements = {}
            for msg in messages:
                partner = msg.get('partner', 'Unknown')
                if partner not in partner_statements:
                    partner_statements[partner] = []
                partner_statements[partner].append(msg.get('message', ''))
            
            # Zbuduj summary wypowiedzi ka≈ºdego partnera
            partner_summaries = "\n".join([
                f"{partner}: {'; '.join(statements[:3])}"  # Pierwsze 3 wypowiedzi
                for partner, statements in partner_statements.items()
            ])
            
            voting_prompt = f"""Na podstawie autonomicznej rozmowy, zasymuluj jak partnerzy zag≈Çosowaliby na poni≈ºszƒÖ decyzjƒô.

PYTANIE DECYZYJNE: {decision_question}

WYPOWIEDZI PARTNER√ìW W ROZMOWIE:
{partner_summaries}

Przeanalizuj stanowiska i zwr√≥ƒá TYLKO JSON:
{{
    "votes": {{
        "Partner1": {{"vote": "ZA", "confidence": 0.8, "reasoning": "dlaczego"}},
        "Partner2": {{"vote": "PRZECIW", "confidence": 0.6, "reasoning": "dlaczego"}},
        "Partner3": {{"vote": "WSTRZYMUJƒò SIƒò", "confidence": 0.5, "reasoning": "dlaczego"}}
    }},
    "predicted_outcome": "ZA" lub "PRZECIW" lub "REMIS",
    "vote_tally": {{"ZA": 2, "PRZECIW": 1, "WSTRZYMUJƒò SIƒò": 1}},
    "confidence_overall": 0.7,
    "key_arguments_for": ["argument 1", "argument 2"],
    "key_arguments_against": ["argument 1", "argument 2"],
    "nexus_recommendation": "Twoja rekomendacja jako meta-advisor"
}}

Mo≈ºliwe g≈Çosy: "ZA", "PRZECIW", "WSTRZYMUJƒò SIƒò"
JSON (bez dodatkowego tekstu):"""
            
            context = {'voting_simulation': True}
            result = nexus.generate_response(voting_prompt, context=context)
            
            if result.get('success'):
                response_text = result.get('response', '').strip()
                
                # Usu≈Ñ markdown blocks
                if response_text.startswith('```'):
                    response_text = response_text.split('```')[1]
                    if response_text.startswith('json'):
                        response_text = response_text[4:]
                    response_text = response_text.strip()
                
                voting_result = json.loads(response_text)
                
                print(f"‚úÖ Nexus Voting Simulation completed")
                print(f"   Predicted outcome: {voting_result.get('predicted_outcome')}")
                print(f"   Confidence: {voting_result.get('confidence_overall', 0)}")
                
                return voting_result
            else:
                print(f"‚ùå Nexus voting simulation failed: {result.get('error')}")
                return None
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd voting simulation: {e}")
            return None
    
    def nexus_knowledge_synthesis(self, recent_conversations: List[Dict], query: str) -> Optional[str]:
        """
        üìö Nexus syntetyzuje wiedzƒô z wielu rozm√≥w
        
        Analizuje wiele ostatnich rozm√≥w i odpowiada na pytanie
        bazujƒÖc na zgromadzonej wiedzy.
        
        Args:
            recent_conversations: Lista ostatnich rozm√≥w (max 5)
            query: Pytanie do Nexusa
        
        Returns:
            Odpowied≈∫ Nexusa lub None
        """
        if not NEXUS_AVAILABLE:
            print("‚ö†Ô∏è Nexus niedostƒôpny - knowledge synthesis pomiƒôta")
            return None
        
        if not recent_conversations:
            return "Brak rozm√≥w do analizy."
        
        try:
            nexus = get_nexus_engine()
            
            # Zbuduj knowledge base z rozm√≥w
            knowledge_base = []
            
            for conv in recent_conversations[:5]:  # Max 5 ostatnich
                topic = conv.get('topic_name', 'Unknown')
                date = conv.get('date', 'Unknown')
                
                # Dodaj summary je≈õli istnieje
                if 'summary' in conv:
                    summary_text = conv['summary'].get('summary', '')
                    key_points = conv['summary'].get('key_points', [])
                    knowledge_base.append(f"[{date}] {topic}: {summary_text} | Kluczowe wnioski: {', '.join(key_points)}")
                else:
                    # Fallback - pierwsze 3 wiadomo≈õci
                    messages = conv.get('messages', [])[:3]
                    msgs_text = '; '.join([f"{m.get('partner')}: {m.get('message', '')[:100]}" for m in messages])
                    knowledge_base.append(f"[{date}] {topic}: {msgs_text}")
            
            knowledge_text = "\n".join(knowledge_base)
            
            synthesis_prompt = f"""Jeste≈õ Nexus - meta-advisor z dostƒôpem do historii autonomicznych rozm√≥w Rady Partner√≥w.

PYTANIE: {query}

BAZA WIEDZY Z OSTATNICH ROZM√ìW:
{knowledge_text}

Na podstawie powy≈ºszej wiedzy, udziel zwiƒôz≈Çej odpowiedzi (max 5-6 zda≈Ñ):
- Syntetyzuj insights z r√≥≈ºnych rozm√≥w
- Wska≈º trendy i wzorce
- Podaj konkretne rekomendacje
- Cytuj konkretne rozmowy je≈õli relevantne

Odpowied≈∫:"""
            
            context = {'knowledge_synthesis': True, 'conversations_count': len(recent_conversations)}
            result = nexus.generate_response(synthesis_prompt, context=context)
            
            if result.get('success'):
                answer = result.get('response', '').strip()
                print(f"‚úÖ Nexus Knowledge Synthesis completed ({len(recent_conversations)} rozm√≥w)")
                return answer
            else:
                print(f"‚ùå Nexus knowledge synthesis failed: {result.get('error')}")
                return None
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd knowledge synthesis: {e}")
            return None


def main():
    """G≈Ç√≥wna funkcja - uruchom autonomicznƒÖ rozmowƒô z Nexus enhancements"""
    engine = AutonomousConversationEngine()
    
    # Wy≈õwietl status API przed rozmowƒÖ
    print("\nüìä Status API przed rozmowƒÖ:")
    engine.tracker.print_status()
    
    # Uruchom rozmowƒô
    conversation = engine.run_conversation(max_messages=12)
    
    if conversation:
        print(f"\n‚úÖ Sukces! ID rozmowy: {conversation['id']}")
        print(f"üìù Liczba wiadomo≈õci: {len(conversation['messages'])}")
        print(f"üî¢ U≈ºyto API calls: {conversation['api_calls_used']}")
        
        # ‚ú® NEXUS ENHANCED FEATURES DEMO
        if NEXUS_AVAILABLE:
            print("\n" + "="*60)
            print("ü§ñ NEXUS ENHANCED FEATURES - DEMO")
            print("="*60)
            
            # 1. Meta-analysis ju≈º zosta≈Ça wykonana w run_conversation()
            if 'nexus_meta_analysis' in conversation:
                meta = conversation['nexus_meta_analysis']
                print(f"\nüìä Meta-Analysis Results:")
                print(f"   Overall Quality: {meta.get('overall_quality', 0):.0%}")
                print(f"   Main Themes: {', '.join(meta.get('main_themes', []))}")
                print(f"   Consensus: {len(meta.get('consensus_points', []))} punkt√≥w")
                print(f"   Disagreements: {len(meta.get('disagreement_points', []))} punkt√≥w")
            
            # 2. Voting Simulation - przyk≈Çadowe pytanie
            print(f"\nüó≥Ô∏è Voting Simulation Example:")
            decision_q = "Czy zwiƒôkszyƒá alokacjƒô w krypto do 30% portfela?"
            voting_result = engine.nexus_voting_simulation(conversation, decision_q)
            
            if voting_result:
                print(f"   Pytanie: {decision_q}")
                print(f"   Predicted Outcome: {voting_result.get('predicted_outcome')}")
                print(f"   Vote Tally: {voting_result.get('vote_tally')}")
                print(f"   Confidence: {voting_result.get('confidence_overall', 0):.0%}")
                print(f"   Nexus Recommendation: {voting_result.get('nexus_recommendation', 'N/A')[:100]}...")
            
            # 3. Knowledge Synthesis - pytanie bazujƒÖce na historii
            recent = engine.get_recent_conversations(limit=5)
            if len(recent) > 0:
                print(f"\nüìö Knowledge Synthesis Example:")
                query = "Jakie sƒÖ najwa≈ºniejsze obawy Rady dotyczƒÖce naszego portfela w ostatnich dyskusjach?"
                synthesis = engine.nexus_knowledge_synthesis(recent, query)
                
                if synthesis:
                    print(f"   Pytanie: {query}")
                    print(f"   Nexus Answer:\n   {synthesis[:300]}...")
        
    else:
        print("\n‚ùå Nie uda≈Ço siƒô przeprowadziƒá rozmowy (brak bud≈ºetu API?)")
    
    # Wy≈õwietl status API po rozmowie
    print("\nüìä Status API po rozmowie:")
    engine.tracker.print_status()


if __name__ == "__main__":
    main()
