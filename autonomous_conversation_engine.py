"""
Autonomous Conversation Engine - Silnik autonomicznych rozm√≥w Rady Partner√≥w
Partnerzy rozmawiajƒÖ ze sobƒÖ nawet gdy ZarzƒÖdzajƒÖcego nie ma
"""

import json
import os
import random
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from api_usage_tracker import get_tracker
import anthropic
import google.generativeai as genai
from openai import OpenAI

# Import konfiguracji z g≈Ç√≥wnego pliku
try:
    from streamlit_app import (
        PERSONAS,
        wczytaj_kodeks, wczytaj_cele, wczytaj_stan_spolki
    )
    IMPORT_OK = True
except Exception as e:
    print(f"‚ö†Ô∏è Nie mo≈ºna zaimportowaƒá z streamlit_app.py: {e}")
    IMPORT_OK = False
    PERSONAS = {}

# API Keys zawsze z .env (bezpieczniej ni≈º import z streamlit_app)
from dotenv import load_dotenv
load_dotenv()
ANTHROPIC_KEY = os.getenv("ANTHROPIC_API_KEY")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")
OPENROUTER_KEY = os.getenv("OPENROUTER_API_KEY")

# Je≈õli PERSONAS nie za≈Çadowano z streamlit_app, spr√≥buj z gra_rpg
if not PERSONAS:
    try:
        import sys
        sys.path.insert(0, os.path.dirname(__file__))
        from gra_rpg import PERSONAS as PERSONAS_FROM_RPG
        PERSONAS = PERSONAS_FROM_RPG
        print("‚úÖ Za≈Çadowano PERSONAS z gra_rpg.py")
    except:
        print("‚ö†Ô∏è Nie mo≈ºna za≈Çadowaƒá PERSONAS")

# Pliki danych
CONVERSATIONS_FILE = "autonomous_conversations.json"
TOPICS_FILE = "autonomous_topics_config.json"

# Domy≈õlne tematy rozm√≥w
DEFAULT_TOPICS = {
    "portfolio_analysis": {
        "name": "Analiza Portfela",
        "description": "PrzeglƒÖd aktualnego stanu portfela i jego alokacji",
        "priority": "MEDIUM",
        "frequency": "daily",
        "prompt_template": "Przeanalizujmy aktualny stan portfela. Warto≈õƒá akcji: {stocks_value} PLN, Krypto: {crypto_value} USD, D≈Çugi: {debt_value} PLN. Jak oceniacie obecnƒÖ alokacjƒô?"
    },
    "market_trends": {
        "name": "Trendy Rynkowe",
        "description": "Dyskusja o aktualnych trendach na rynkach",
        "priority": "LOW",
        "frequency": "weekly",
        "prompt_template": "Co sƒÖdzicie o aktualnych trendach rynkowych? Bitcoin ostatnio {btc_trend}, rynek akcji {stock_trend}."
    },
    "risk_assessment": {
        "name": "Ocena Ryzyka",
        "description": "Analiza ryzyka w portfelu",
        "priority": "HIGH",
        "frequency": "daily",
        "prompt_template": "Przeanalizujmy poziom ryzyka w portfelu. Czy jeste≈õmy odpowiednio zdywersyfikowani? Jakie sƒÖ najwiƒôksze zagro≈ºenia?"
    },
    "goals_review": {
        "name": "PrzeglƒÖd Cel√≥w",
        "description": "Dyskusja o postƒôpach w realizacji cel√≥w",
        "priority": "MEDIUM",
        "frequency": "weekly",
        "prompt_template": "Sprawd≈∫my postƒôpy w realizacji naszych cel√≥w finansowych. Czy jeste≈õmy na dobrej drodze?"
    },
    "strategy_debate": {
        "name": "Debata Strategiczna",
        "description": "Dyskusja o d≈Çugoterminowej strategii",
        "priority": "HIGH",
        "frequency": "weekly",
        "prompt_template": "Porozmawiajmy o naszej d≈Çugoterminowej strategii inwestycyjnej. Czy powinna siƒô zmieniƒá? Co dostosowaƒá?"
    }
}


class AutonomousConversationEngine:
    """Silnik autonomicznych rozm√≥w"""
    
    def __init__(self):
        self.tracker = get_tracker()
        self.topics_config = self._load_topics_config()
        self.conversations_db = self._load_conversations()
        
        # Konfiguruj AI clients
        self.claude_client = anthropic.Anthropic(api_key=ANTHROPIC_KEY) if ANTHROPIC_KEY else None
        if GEMINI_KEY:
            genai.configure(api_key=GEMINI_KEY)
        
        # OpenRouter client (NIE standardowy OpenAI!)
        if OPENROUTER_KEY:
            self.openai_client = OpenAI(
                api_key=OPENROUTER_KEY,
                base_url="https://openrouter.ai/api/v1"
            )
        else:
            self.openai_client = None
        
        print("‚úÖ Autonomous Conversation Engine initialized")
    
    def _load_topics_config(self) -> Dict:
        """Za≈Çaduj konfiguracjƒô temat√≥w"""
        if os.path.exists(TOPICS_FILE):
            with open(TOPICS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            self._save_topics_config(DEFAULT_TOPICS)
            return DEFAULT_TOPICS
    
    def _save_topics_config(self, config: Dict):
        """Zapisz konfiguracjƒô temat√≥w"""
        with open(TOPICS_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def _load_conversations(self) -> List[Dict]:
        """Za≈Çaduj historiƒô rozm√≥w"""
        if os.path.exists(CONVERSATIONS_FILE):
            with open(CONVERSATIONS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return []
    
    def _save_conversation(self, conversation: Dict):
        """Zapisz rozmowƒô do bazy"""
        self.conversations_db.append(conversation)
        
        # Zachowaj ostatnie 100 rozm√≥w
        if len(self.conversations_db) > 100:
            self.conversations_db = self.conversations_db[-100:]
        
        with open(CONVERSATIONS_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.conversations_db, f, indent=2, ensure_ascii=False)
    
    def check_api_budget(self) -> Tuple[bool, str]:
        """
        Sprawd≈∫ czy jest dostƒôpny bud≈ºet API dla autonomicznej rozmowy
        
        Returns:
            (can_proceed, message)
        """
        budgets = self.tracker.get_all_budgets()
        
        # Sprawd≈∫ czy kt√≥rekolwiek API ma dostƒôpny bud≈ºet
        available_apis = []
        for api_name, budget in budgets.items():
            if budget["autonomous"]["remaining"] > 8:  # Min 8 wywo≈Ça≈Ñ na rozmowƒô (4 partner√≥w x 2)
                available_apis.append(api_name)
        
        if not available_apis:
            return False, "üö´ Brak dostƒôpnego bud≈ºetu API dla autonomicznych rozm√≥w dzisiaj"
        
        return True, f"‚úÖ Dostƒôpne API: {', '.join(available_apis)}"
    
    def select_topic(self) -> Tuple[str, Dict]:
        """
        Wybierz temat do dyskusji
        
        Returns:
            (topic_id, topic_config)
        """
        # Mo≈ºesz dodaƒá bardziej zaawansowanƒÖ logikƒô (np. AI decyduje)
        # Na razie: losowy temat z HIGH priority
        
        high_priority = {k: v for k, v in self.topics_config.items() if v.get("priority") == "HIGH"}
        
        if high_priority:
            topic_id = random.choice(list(high_priority.keys()))
        else:
            topic_id = random.choice(list(self.topics_config.keys()))
        
        return topic_id, self.topics_config[topic_id]
    
    def generate_opening_prompt(self, topic: Dict) -> str:
        """Wygeneruj poczƒÖtkowy prompt rozmowy"""
        template = topic.get("prompt_template", "Porozmawiajmy o {topic_name}")
        
        # Podstaw rzeczywiste dane (je≈õli IMPORT_OK)
        try:
            stan_spolki = wczytaj_stan_spolki() if IMPORT_OK else {}
            
            prompt = template.format(
                stocks_value=stan_spolki.get('akcje_wartosc', 0),
                crypto_value=stan_spolki.get('krypto_wartosc', 0),
                debt_value=stan_spolki.get('dlugi_laczne', 0),
                btc_trend="ro≈õnie" if random.random() > 0.5 else "spada",
                stock_trend="stabilny" if random.random() > 0.5 else "zmniejsza siƒô",
                topic_name=topic.get("name", "temat")
            )
        except:
            prompt = f"Porozmawiajmy o: {topic.get('name', 'strategii')}"
        
        return prompt
    
    def select_participants(self, topic: Dict) -> List[str]:
        """
        Wybierz uczestnik√≥w rozmowy (4 partner√≥w)
        
        WA≈ªNE: Wykluczamy "Partner ZarzƒÖdzajƒÖcy (JA)" - to fizyczna osoba!
        Autonomiczne rozmowy = tylko AI partners bez u≈ºytkownika
        """
        if not PERSONAS:
            return ["Nexus", "Warren Buffett", "George Soros", "Changpeng Zhao (CZ)"]
        
        all_partners = list(PERSONAS.keys())
        
        # ‚ùå WYKLUCZAMY "Partner ZarzƒÖdzajƒÖcy (JA)" z autonomicznych rozm√≥w!
        ai_only_partners = [p for p in all_partners if p != "Partner ZarzƒÖdzajƒÖcy (JA)"]
        
        # Wybierz 4 AI partner√≥w (Nexus, Warren, Soros, CZ)
        # Mo≈ºesz dodaƒá logikƒô: risk topics = Soros first, value = Buffett first, crypto = CZ first
        participants = ai_only_partners[:4] if len(ai_only_partners) >= 4 else ai_only_partners
        
        return participants
    
    def call_ai_partner(self, partner_name: str, prompt: str, context: List[Dict]) -> Optional[str]:
        """
        Wy≈õlij prompt do AI partnera
        
        Args:
            partner_name: Nazwa partnera
            prompt: G≈Ç√≥wny prompt
            context: Lista poprzednich wiadomo≈õci [{"partner": "...", "message": "..."}]
        
        Returns:
            Odpowied≈∫ AI lub None je≈õli b≈ÇƒÖd
        """
        if not PERSONAS or partner_name not in PERSONAS:
            return None
        
        persona = PERSONAS[partner_name]
        model_engine = persona.get("model_engine", "gemini")
        
        # Mapuj model_engine na api_type dla trackera
        if model_engine.startswith("openrouter"):
            api_type = "openai"  # OpenRouter u≈ºywa OpenAI API
        else:
            api_type = model_engine  # "gemini" lub "claude"
        
        # Sprawd≈∫ bud≈ºet przed wywo≈Çaniem
        if not self.tracker.can_make_autonomous_call(api_type):
            print(f"‚ö†Ô∏è Brak bud≈ºetu {api_type} dla {partner_name}")
            return None
        
        # Przygotuj pe≈Çny prompt z kontekstem
        full_prompt = f"""Jeste≈õ {partner_name}.

{persona.get('opis', '')}

WA≈ªNE: To jest autonomiczna rozmowa Rady Partner√≥w (ZarzƒÖdzajƒÖcego nie ma).
Rozmawiasz z kolegami z Rady. BƒÖd≈∫ zwiƒôz≈Çy (max 3-4 zdania).
"""
        
        # Dodaj kontekst poprzednich wypowiedzi
        if context:
            full_prompt += "\n\nüí¨ POPRZEDNIE WYPOWIEDZI:\n"
            for msg in context[-3:]:  # Ostatnie 3 wiadomo≈õci
                full_prompt += f"{msg['partner']}: {msg['message']}\n"
        
        full_prompt += f"\n\nTemat dyskusji: {prompt}\n\nTwoja odpowied≈∫ (zwiƒô≈∫le, 3-4 zdania):"
        
        # Wywo≈Çaj odpowiednie API na podstawie model_engine
        try:
            # OPENROUTER (wszystkie modele openrouter_*)
            if model_engine.startswith("openrouter") and self.openai_client:
                # Mapuj model_engine na konkretny model OpenRouter (z :free!)
                model_map = {
                    "openrouter_mistral": "mistralai/mistral-7b-instruct:free",
                    "openrouter_llama": "meta-llama/llama-4-maverick:free",
                    "openrouter_mixtral": "meta-llama/llama-4-scout:free",
                    "openrouter_glm": "z-ai/glm-4.5-air:free"
                }
                model_name = model_map.get(model_engine, "mistralai/mistral-7b-instruct:free")
                
                response = self.openai_client.chat.completions.create(
                    model=model_name,
                    max_tokens=300,
                    messages=[{"role": "user", "content": full_prompt}]
                )
                answer = response.choices[0].message.content
                
            # GEMINI
            elif model_engine == "gemini":
                model = genai.GenerativeModel('gemini-2.0-flash-exp')
                response = model.generate_content(full_prompt)
                answer = response.text
                
            # CLAUDE
            elif model_engine == "claude" and self.claude_client:
                response = self.claude_client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=300,
                    messages=[{"role": "user", "content": full_prompt}]
                )
                answer = response.content[0].text
            else:
                print(f"‚ùå Nieznany model_engine: {model_engine}")
                return None
            
            # Oczy≈õƒá odpowied≈∫ z token√≥w specjalnych
            answer = answer.strip()
            # Usu≈Ñ tokeny: <s>, </s>, <|endoftext|>, itp.
            for token in ['<s>', '</s>', '<|endoftext|>', '<|im_end|>', 'ÔøΩ']:
                answer = answer.replace(token, '')
            answer = answer.strip()
            
            # Zarejestruj wywo≈Çanie
            self.tracker.track_call(api_type, is_autonomous=True)
            
            return answer
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd wywo≈Çania {api_type} dla {partner_name}: {e}")
            return None
    
    def run_conversation(self, max_messages: int = 12) -> Optional[Dict]:
        """
        Uruchom autonomicznƒÖ rozmowƒô
        
        Args:
            max_messages: Maksymalna liczba wiadomo≈õci (domy≈õlnie 12)
        
        Returns:
            Dict z rozmowƒÖ lub None je≈õli b≈ÇƒÖd
        """
        print("\n" + "="*60)
        print("ü§ñ AUTONOMOUS CONVERSATION ENGINE - START")
        print("="*60)
        
        # 1. Sprawd≈∫ bud≈ºet API
        can_proceed, budget_msg = self.check_api_budget()
        print(budget_msg)
        
        if not can_proceed:
            return None
        
        # 2. Wybierz temat
        topic_id, topic = self.select_topic()
        print(f"üìã Temat: {topic['name']} (Priority: {topic['priority']})")
        
        # 3. Wybierz uczestnik√≥w
        participants = self.select_participants(topic)
        print(f"üë• Uczestnicy: {', '.join(participants)}")
        
        # 4. Wygeneruj opening prompt
        opening_prompt = self.generate_opening_prompt(topic)
        print(f"üí¨ Opening: {opening_prompt[:100]}...")
        
        # 5. Rozpocznij rozmowƒô
        conversation = {
            "id": f"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "date": datetime.now().isoformat(),
            "topic_id": topic_id,
            "topic_name": topic['name'],
            "opening_prompt": opening_prompt,  # ‚úÖ DODANE: Pe≈Çny tekst opening
            "participants": participants,
            "messages": [],
            "status": "in_progress",
            "api_calls_used": 0
        }
        
        context = []
        
        for i in range(max_messages):
            # Rotuj uczestnik√≥w
            current_partner = participants[i % len(participants)]
            
            print(f"\n[{i+1}/{max_messages}] üó£Ô∏è {current_partner} odpowiada...")
            
            # Wywo≈Çaj AI
            response = self.call_ai_partner(current_partner, opening_prompt, context)
            
            if response:
                message = {
                    "partner": current_partner,
                    "message": response,
                    "timestamp": datetime.now().isoformat(),
                    "message_number": i + 1
                }
                
                conversation["messages"].append(message)
                context.append({"partner": current_partner, "message": response})
                conversation["api_calls_used"] += 1
                
                print(f"   ‚úÖ {response[:150]}...")
            else:
                print(f"   ‚ö†Ô∏è Brak odpowiedzi (limit API?)")
                # Je≈õli 3 kolejne b≈Çƒôdy, przerwij
                if i > 0 and all(m is None for m in conversation["messages"][-3:]):
                    print("   üö´ Zbyt wiele b≈Çƒôd√≥w, przerywam rozmowƒô")
                    break
        
        # 6. Zako≈Ñcz rozmowƒô
        conversation["status"] = "completed"
        conversation["completed_at"] = datetime.now().isoformat()
        
        # 7. Zapisz do bazy
        self._save_conversation(conversation)
        self.tracker.increment_autonomous_conversation()
        
        print(f"\n‚úÖ Rozmowa zako≈Ñczona: {len(conversation['messages'])} wiadomo≈õci")
        print(f"üíæ Zapisano jako: {conversation['id']}")
        
        # 8. Wygeneruj AI Summary (je≈õli sƒÖ wiadomo≈õci)
        if len(conversation['messages']) > 0:
            print(f"ü§ñ Generujƒô AI Summary...")
            summary = self._generate_summary(conversation)
            if summary:
                conversation['summary'] = summary
                self._save_conversation(conversation)  # Zapisz ze summary
                print(f"‚úÖ Summary wygenerowane")
        
        # 9. Wy≈õlij email notification (je≈õli w≈ÇƒÖczone)
        try:
            from email_notifier import get_conversation_notifier
            notifier = get_conversation_notifier()
            if notifier.config.get("enabled", False):
                notifier.send_conversation_completed(conversation)
                print(f"üìß Email notification wys≈Çany")
        except Exception as e:
            print(f"‚ö†Ô∏è Nie mo≈ºna wys≈Çaƒá email notification: {e}")
        
        print("="*60 + "\n")
        
        return conversation
    
    def _generate_summary(self, conversation: Dict) -> Optional[Dict]:
        """
        Wygeneruj AI summary rozmowy u≈ºywajƒÖc Gemini
        
        Returns:
            Dict z polami: summary, key_points, sentiment
            None je≈õli b≈ÇƒÖd
        """
        try:
            messages = conversation.get("messages", [])
            if not messages:
                return None
            
            # Zbuduj transkrypt
            transcript = "\n".join([
                f"{msg.get('partner', 'Unknown')}: {msg.get('message', '')[:300]}"  # Max 300 znak√≥w na msg
                for msg in messages
            ])
            
            topic_name = conversation.get("topic_name", "Unknown Topic")
            
            prompt = f"""Przeanalizuj tƒô rozmowƒô Rady Partner√≥w i wygeneruj zwiƒôz≈Çe podsumowanie.

TEMAT ROZMOWY: {topic_name}

TRANSKRYPT:
{transcript}

Wygeneruj odpowied≈∫ w formacie JSON z nastƒôpujƒÖcymi polami:
1. "summary": Kr√≥tkie podsumowanie rozmowy (2-3 zdania max)
2. "key_points": Lista 3 najwa≈ºniejszych wniosk√≥w (kr√≥tkie zdania)
3. "sentiment": "positive" lub "neutral" lub "negative" (og√≥lny ton rozmowy)

Odpowied≈∫ TYLKO w formacie JSON, bez dodatkowego tekstu:
"""
            
            # Wywo≈Çaj Gemini
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            response = model.generate_content(prompt)
            
            # Parse JSON
            response_text = response.text.strip()
            
            # Usu≈Ñ markdown code blocks je≈õli sƒÖ
            if response_text.startswith('```'):
                response_text = response_text.split('```')[1]
                if response_text.startswith('json'):
                    response_text = response_text[4:]
                response_text = response_text.strip()
            
            summary_data = json.loads(response_text)
            
            # Track API call
            self.tracker.track_call('gemini', is_autonomous=True)
            
            return summary_data
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd generowania summary: {e}")
            return None
    
    def get_recent_conversations(self, limit: int = 10) -> List[Dict]:
        """Zwr√≥ƒá ostatnie N rozm√≥w"""
        return sorted(self.conversations_db, key=lambda x: x.get("date", ""), reverse=True)[:limit]
    
    def get_conversation_by_id(self, conv_id: str) -> Optional[Dict]:
        """Zwr√≥ƒá konkretnƒÖ rozmowƒô po ID"""
        for conv in self.conversations_db:
            if conv.get("id") == conv_id:
                return conv
        return None


def main():
    """G≈Ç√≥wna funkcja - uruchom autonomicznƒÖ rozmowƒô"""
    engine = AutonomousConversationEngine()
    
    # Wy≈õwietl status API przed rozmowƒÖ
    print("\nüìä Status API przed rozmowƒÖ:")
    engine.tracker.print_status()
    
    # Uruchom rozmowƒô
    conversation = engine.run_conversation(max_messages=12)
    
    if conversation:
        print(f"\n‚úÖ Sukces! ID rozmowy: {conversation['id']}")
        print(f"üìù Liczba wiadomo≈õci: {len(conversation['messages'])}")
        print(f"üî¢ U≈ºyto API calls: {conversation['api_calls_used']}")
    else:
        print("\n‚ùå Nie uda≈Ço siƒô przeprowadziƒá rozmowy (brak bud≈ºetu API?)")
    
    # Wy≈õwietl status API po rozmowie
    print("\nüìä Status API po rozmowie:")
    engine.tracker.print_status()


if __name__ == "__main__":
    main()
